---
title: "STATS205P_Project"
output: html_document
date: "2024-05-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Clean Data
```{r}
library(rstan)

data <- read.csv("Sleep_health_and_lifestyle_dataset.csv", header = TRUE)
columns_to_drop <- c("Person.ID", "Sleep.Duration", 
                      "High.Blood.Pressure", "Low.Blood.Pressure", "Daily.Steps", 
                     "BMI.Category", "Heart.Rate")
clean_data <- data[, -which(names(data) %in% columns_to_drop)]
clean_data <- clean_data %>%
  filter(Occupation != "Manager", Occupation != "Sales Representative", Occupation != "Software Engineer", Occupation != "Scientist")


clean_data$Gender <- as.integer(clean_data$Gender == "Male")
clean_data$Occupation <- as.factor(clean_data$Occupation)

sleep_data <- clean_data
sleep_data$Sleep.Category <- ifelse(sleep_data$Sleep.Disorder == "None", 0, 1)
colnames(sleep_data)
sleep_data
```

## Stan Model

```{r}
stan_code <- "
data {
  int<lower=1> D; // # of features 6 
  int<lower=0> N; // # of observations 374
  int<lower=1> L; // # occupations 10
  array[N] int<lower=0> y; 
  array[N] int<lower=1, upper=L> ll;
  array[N] row_vector[D] x;
}
parameters {
  array[D] real<lower=0> tau;
  real<lower=0> tau_o; 
  real<lower=0> tau_d; 
  real<lower=0> tau_h; 
  real<lower=0> tau_i; 
  array[L] vector[D] beta;
  real<lower=0> sigma_y;
}

model {
  sigma_y ~ scaled_inv_chi_square(1, 0.05); 
  tau_o ~ scaled_inv_chi_square(1, 0.05); 
  tau_h ~ scaled_inv_chi_square(1, tau_o); 
  tau_d ~ scaled_inv_chi_square(1, tau_o); 
  tau_i ~ scaled_inv_chi_square(1, tau_o); 
  
  tau[1] ~ scaled_inv_chi_square(1, tau_i);
  tau[2:3] ~  scaled_inv_chi_square(1, tau_d);
  tau[4:5] ~  scaled_inv_chi_square(1, tau_h);
  
  for (d in 1:D) {
    for (l in 1:L) {
      beta[l, d] ~ normal(0, tau[d]);
    }
  }
  
  for (n in 1:N) {
    y[n] ~ normal(x[n] * beta[ll[n]], sigma_y);
  }
}

generated quantities {
  // Define a new variable 'predicted_y' based on model parameters and data
  vector[N] predicted_y;
  
  for (n in 1:N) {
    predicted_y[n] = normal_rng(x[n] * beta[ll[n]], sigma_y);
  }
}
"

stan_model <- stan_model(model_code = stan_code)
```

## Run Model

```{r}
###############################################################################
# Check the influence of the stress level on having sleep disorder #
###############################################################################


# Extract relevant columns for x and ll
x <- as.matrix(sleep_data[, c("Gender", "Age", "Physical.Activity.Level", "Stress.Level")])
x_0 <- rep(1, nrow(x)) # Create a column of ones
x_with_intercept <- cbind(x_0, x) # Combine the intercept term with the original matrix
dim(x_with_intercept)

D <- dim(x_with_intercept)[2]  # Number of features + intercept
N <- nrow(sleep_data) # Number of data points
L <- length(unique(sleep_data$Occupation))  # Number of levels for 'category'
ll <- as.integer((sleep_data$Occupation))
y = sleep_data$Quality.of.Sleep
# Prepare data list
data_list <- list(
  D = D,
  N = N,
  L = L,
  y = y,
  ll = ll,  # Use matrix instead of array
  x = x_with_intercept
)

fit1 <- sampling(stan_model, data = data_list)
```

## Show Results

```{r}
# Plot traceplots to check convergence
traceplot(fit1, pars = c( "tau_o", "tau_d", "tau_h", "tau_i"))
traceplot(fit1, pars = c("beta"))

```

```{r}
# Load necessary packages
library(rstan)
library(bayesplot)

# Print summary of the model fit
print(fit1)

# Summary of the model parameters
summary_fit1 <- summary(fit1, pars = c("tau", "tau_o", "tau_d", "tau_h", "tau_i", "beta", "sigma_y"))
print(summary_fit1)

# Extract the posterior samples
posterior_samples <- extract(fit1)

# Plot posterior distributions for key parameters
mcmc_areas(posterior_samples, pars = c("tau", "tau_o", "tau_d", "tau_h", "tau_i", "sigma_y"))

# Plot trace plots to diagnose convergence
mcmc_trace(posterior_samples, pars = c("tau", "tau_o", "tau_d", "tau_h", "tau_i", "sigma_y"))

# You can also plot pair plots for selected parameters to check for correlations
mcmc_pairs(posterior_samples, pars = c("tau", "tau_o", "tau_d", "tau_h", "tau_i", "sigma_y"))

```


## Evaluate the Model
Posterior Predictive Checks
```{r}
library(rstan)
library(ggplot2)
library(bayesplot)

posterior_samples <- extract(fit1)
n_samples <- length(posterior_samples$sigma_y)

# Generate posterior predictive samples
y_rep <- matrix(NA, nrow = n_samples, ncol = N)
for (i in 1:n_samples) {
  beta_i <- posterior_samples$beta[i,,]
  sigma_y_i <- posterior_samples$sigma_y[i]
  for (n in 1:N) {
    y_rep[i, n] <- rnorm(1, mean = x_with_intercept[n, ] %*% beta_i[ll[n], ], sd = sigma_y_i)
  }
}

y_rep <- as.matrix(y_rep)
# Plot posterior predictive checks
ppc_dens_overlay(y, y_rep[1:100, ])  # Overlay density plots (using first 100 samples for clarity)

# You can also use other ppc functions from bayesplot for more checks
ppc_intervals(y, y_rep)  # Intervals plot


df_sim_means <- data.frame(mean_y = rowMeans(y_rep), model = "Simulated")
df_observed <- data.frame(mean_y = mean(y), model = "Observed")
ggplot(df_sim_means, aes(x = mean_y, fill = model)) +
  geom_density(alpha = 0.5) +
  geom_vline(aes(xintercept = mean(y)), color = "red", linetype = "dashed") +
  labs(title = "Distribution of Simulated Means",
       x = "Mean of Simulated Y",
       y = "Density",
       fill = "Model") +
  theme_minimal()
```
```{r}

predicted_values <- extract(fit1)$predicted_y
predicted_means <- apply(predicted_values, 2, mean)
predicted_means_vector <- as.vector(predicted_means)

# Actual values (response variable)
actual_values <- sleep_data$Quality.of.Sleep

# Mean Squared Error (MSE)
mse <- mean((predicted_means_vector - actual_values)^2)

# Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)

# Mean Absolute Error (MAE)
mae <- mean(abs(predicted_means_vector - actual_values))

# R-squared (R²)
ss_residual <- sum((actual_values - predicted_means_vector)^2)
ss_total <- sum((actual_values - mean(actual_values))^2)
r_squared <- 1 - (ss_residual / ss_total)

# Print the metrics
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("R-squared (R²):", r_squared, "\n")

```

```{r}
library(caret)

# Define the training control
ctrl <- trainControl(method = "cv",   # Cross-validation method
                     number = 5,      # Number of folds
                     verboseIter = TRUE)  # Print progress

# Define the linear regression model
model <- train(Quality.of.Sleep ~ Gender + Age + Physical.Activity.Level + Stress.Level,                    
               data = sleep_data,       # Training data
               method = "lm",           # Linear regression model
               trControl = ctrl)        # Use defined training control

# Print the trained model
print(model)

# Get the cross-validated performance metrics
performance_metrics <- model$results
print(performance_metrics)

```




## Interprete the Results

```{r}
# Extracting samples from the fitted model
samples <- extract(fit1)

# 1. Examine Coefficients
fit_summary <- summary(fit1)
summary_table <- fit_summary$summary
beta_rows <- grepl("beta", rownames(summary_table))
coef_summary <- summary_table[beta_rows, ]
#print(coef_summary)

beta_samples <- samples$beta
coef_summary <- apply(beta_samples, c(2, 3), mean)
print(coef_summary)

# 3. Compare Occupations
occupation_coef <- coef_summary[, 5]
print(occupation_coef)
occupation_names <- levels(as.factor(sleep_data$Occupation))
barplot(occupation_coef, names.arg = occupation_names, las = 2,
        xlab = "Occupation", ylab = "Coefficient for Stress.Level")

```






